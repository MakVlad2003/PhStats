{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "779-UxHp3h8R"
   },
   "source": [
    "### *Профиль биология*\n",
    "\n",
    "Набор данных включает 171 молекулу, предназначенную для функциональных доменов белка CRY1, ответственного за формирование циркадного ритма. 56 молекул токсичны, а остальные нетоксичны.\n",
    "\n",
    "Полученные данные представляют собой полный набор из 1203 молекулярных дескрипторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zy-x7atXGekR"
   },
   "source": [
    "Данное домашнее задание имеет свободную форму, то есть вашей задачей будет для каждого класса моделей получить лучший результат и после выбрать наилучшую модель. Метрика для задачи - `from sklearn.metrics import f1_score`. Работа будет оцениваться по следующим ключевым пунктам:\n",
    "\n",
    "\n",
    "1.   Предвартельный анализ данных\n",
    "2.   Предобработка данных\n",
    "  1.   Обработка пропусков\n",
    "  2.   Обработка выбросов\n",
    "\n",
    "3.   Реализация моделей\n",
    "  1.  Дерево\n",
    "  2.  Лес\n",
    "  3.  Логистическая регрессия\n",
    "  4.  KNN\n",
    "  5.  MLP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHPwwPcdJ_5g"
   },
   "source": [
    "## Предварительный анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqsS6q2_QZA_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, classification_report, f1_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "plt.style.use('classic')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPCt1wT4ywIK"
   },
   "source": [
    "Исходя из описания, наша задача будет состоять в классификации молекул на токсичные и нетоксичные на основе их молекулярных дескрипторов. Следовательно, мы будем решать задачу бинарной классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iioJPx-HKleJ"
   },
   "source": [
    "В этом разделе ожидается, что вы посмотрите на распределение признаков и классов, изучите их связь, проанализируете признаки на наличие в них пропусков или выбросов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIbR09AdEXML"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/data_bio.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYakJ7djvHU1"
   },
   "source": [
    "Посмотрим на первые строки этой таблицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "itCHkJY7vLDS",
    "outputId": "33e00f66-2e38-4067-a7a8-2cfbdd5b6330"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMAY70ERvzoa"
   },
   "source": [
    "Посмотрим на типы данных в нашей таблице:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxR61Opkv3f8",
    "outputId": "84b64746-9a08-4ce5-93c2-a6c405d670ea"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoGzG9iztg3I"
   },
   "source": [
    "Посмотрим на описательные стаистики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "Agq6i1clthD1",
    "outputId": "f86f1d88-4e92-4174-d3bc-7844f6913e27"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VqzNhuWwjZA"
   },
   "source": [
    "Проверим, имеются ли в нашем данных пропуски. Если да, то удалим их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5KA-4r4y5Gv",
    "outputId": "99168a27-2108-4b11-bbbc-a771db6d4c33"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmy7MsyjzYGx"
   },
   "source": [
    "Видно, что таргетная переменная `Class` является категориальной. Заменим `NonToxic` на 0, а `Toxic` на 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "FbpCdB1IztIK",
    "outputId": "0408c3e5-37a4-428f-8d3e-4ef1c5c56add"
   },
   "outputs": [],
   "source": [
    "df['Class_Toxic'] = df['Class'].map({'NonToxic': 0, 'Toxic': 1})\n",
    "df.drop('Class', axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdV7GsWcxN0r"
   },
   "source": [
    "Так как наш датасет содержит большое число фичей, то давайте с помощью модели случайного леса отберем 10 наиболее важных и продолжим работать с ними:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eoMJgeQNxY-4",
    "outputId": "64e469c0-d840-4517-e2d7-324e2501c12b"
   },
   "outputs": [],
   "source": [
    "features = df.drop('Class_Toxic', axis = 1)\n",
    "target = df['Class_Toxic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.2, random_state = 42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = pd.DataFrame({'Feature': features.columns, 'Importance': rf_classifier.feature_importances_})\n",
    "feature_importances_10 = feature_importances.sort_values(by = 'Importance', ascending = False)[:10]\n",
    "\n",
    "print(feature_importances_10['Feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1-woD85-_sA"
   },
   "source": [
    "Преобразуем датасет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "WZqQS1S4_DOC",
    "outputId": "99fefabb-f896-4ac4-9d7d-1ef1b24f87f9"
   },
   "outputs": [],
   "source": [
    "#imp_feat = [\"ATSC8c\", \"MATS1e\", \"minsCH3\", \"MATS4e\", \"MATS4s\", \"ATSC7i\", \"SpMin4_Bhp\", \"MLFER_S\", \"ATSC4p\", \"SpMax2_Bhm\"] # признаки из статьи\n",
    "imp_feat = ['ATSC7p', 'SpMax_Dt', 'MDEC-23', 'SpMax3_Bhi', 'ZMIC1', 'ATSC1v', 'MWC2', 'TIC0', 'MATS7p', 'SpMax8_Bhi']\n",
    "data = df[imp_feat]\n",
    "data['Class_Toxic'] = df['Class_Toxic']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYcFr4YXAOxZ"
   },
   "source": [
    "Посмотрим на гистограммы и ядерные оценки плотности для всех признаков из датасета отдельно для каждого класса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Te2AR9j8AYMa",
    "outputId": "4c72dd4e-77e9-42d4-e0de-a435d6dd50e8"
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "for feature in data.columns[:-1]:\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize = (12, 5))\n",
    "    plt.subplots_adjust(wspace = 0.5)\n",
    "\n",
    "    sns.histplot(data = data, x = feature, hue = 'Class_Toxic', alpha = 0.5, ax = axs[0])\n",
    "    axs[0].set_title(f'Гистограмма для {feature}', fontsize = 10)\n",
    "    axs[0].set_facecolor('white')\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    sns.kdeplot(data = data, x = feature, hue = 'Class_Toxic', common_norm = True, ax = axs[1])\n",
    "    axs[1].set_title(f'KDE для {feature}', fontsize = 10)\n",
    "    axs[1].set_facecolor('white')\n",
    "    axs[1].grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsAbYOTgBJnP"
   },
   "source": [
    "**Выводы:**\n",
    "\n",
    "1) Во всех графиках виден дисбаланс между классами.\n",
    "\n",
    "2) Из KDE видно, что распределения стремятся к нормальному.\n",
    "\n",
    "3) Также видно, что для большинства признаков, максимумы распредения плотности совпадают."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7305eYMCMpv"
   },
   "source": [
    "Из гистограмм и KDE видно, что выбросы в даннных присутсвуют. Убедимся в этом, используя `box-plot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "id": "gYp4oRvkCgtN",
    "outputId": "5dbca702-aa9e-40e9-f8ee-fbe801d3fb64"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 40))\n",
    "\n",
    "num_rows = 10\n",
    "num_cols = 5\n",
    "\n",
    "for i, feature in enumerate(imp_feat, 1):\n",
    "    plt.subplot(num_rows, num_cols, i)\n",
    "    sns.boxplot(data = data[feature], color = 'skyblue', width = 0.5)\n",
    "\n",
    "    plt.title(f'{feature}', fontsize = 15)\n",
    "    plt.xlabel('Count', fontsize = 15)\n",
    "    plt.ylabel(None)\n",
    "\n",
    "    plt.xticks(fontsize = 12)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUZPYtsCEaPJ"
   },
   "source": [
    "**Выводы:** Теперь выбросы стали более наглядными.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvcRb5NKMF_a"
   },
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6o21LUtMPDI"
   },
   "source": [
    "В этом разделе ожидается, что вы обработаете пропуски (если они есть) с помощью линейной регрессии, а выбросы (если они есть) обработайте способом на ваше усмотрение. Для оценки качества обработки пропусков используйте метрику MAPE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMVqu88IJz4H"
   },
   "source": [
    "Создадим массив признаков и массив таргета. Разобьем наши данные на обучающую и тестовую выборки в отношении 7:3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kfOeq3_SsiTG",
    "outputId": "c815dd5f-567c-4f14-ef8b-d3598e3f04c7"
   },
   "outputs": [],
   "source": [
    "X = df.drop('Class_Toxic', axis = 1)\n",
    "y = df['Class_Toxic']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_lHcvKfGkHE"
   },
   "source": [
    "Для борьбы с выбросами применим стандартизацию данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mjaeaLmyKKvf"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aE6V_GVCKjkg"
   },
   "source": [
    "Давайте посмотрим на распределение наших данных по целевой переменной по всему датасету, тренировочной и тестовой выборках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "xhtfuvOVKhqP",
    "outputId": "b10148f9-6355-49b6-ea9b-a52c1bbb9d64"
   },
   "outputs": [],
   "source": [
    "original = df['Class_Toxic'].value_counts()\n",
    "train = y_train.value_counts()\n",
    "test = y_test.value_counts()\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize = (15, 5))\n",
    "sns.barplot(x = original.index, y = original.values, ax = axes[0], palette = ['blue'])\n",
    "axes[0].set_title('Распределение классов в df')\n",
    "axes[0].set_ylabel('Количество')\n",
    "\n",
    "sns.barplot(x = train.index, y = train.values, ax = axes[1], palette = ['green'])\n",
    "axes[1].set_title('Распределение классов в train')\n",
    "\n",
    "sns.barplot(x = test.index, y = test.values, ax = axes[2], palette = ['orange'])\n",
    "axes[2].set_title('Распределение классов в test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHVgYf24MCet"
   },
   "source": [
    "Теперь видно, что между классами сильный перекос."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIvTjeLIPLRS"
   },
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naib00-bVrRe"
   },
   "source": [
    "Для лучшей точности перед обучением каждой модели будем делать поиск по сетке. Также не будем забывать про дисбаланс классов. Все параметры для GreadSearchCV были взяты из документации sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lm_2Vo95QqHt"
   },
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrIRhSS2V2_0",
    "outputId": "2c461688-a250-424a-e545-2787a31c480c"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 6],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "tree_classifier = DecisionTreeClassifier(random_state = 42)\n",
    "\n",
    "# pos_label = 1 - учитывает дисбаланс классов при использовании F1-score\n",
    "scorer = make_scorer(f1_score, pos_label = 1)\n",
    "grid_search = GridSearchCV(estimator=tree_classifier, param_grid = param_grid, cv = 5, scoring = scorer)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Наилучшие параметры:', grid_search.best_params_)\n",
    "print(f'F1 с учетом сбалансированных классов: {grid_search.best_score_:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9--zmnfRTl_"
   },
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mvSDNyRwR6sm",
    "outputId": "7db987ab-d03e-45c9-9006-a08c12f26179"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "forest_classifier = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "scorer = make_scorer(f1_score, pos_label = 1)\n",
    "grid_search = GridSearchCV(estimator = forest_classifier, param_grid = param_grid, cv = 5, scoring = scorer)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Наилучшие параметры:', grid_search.best_params_)\n",
    "print(f'F1 с учетом сбалансированных классов: {grid_search.best_score_:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ucz276CrSV1L"
   },
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fzmlg6liSb2z",
    "outputId": "794b3933-4c4c-4e04-d4af-8daf78a7b194"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "logreg_classifier = LogisticRegression(random_state = 42, solver = 'liblinear')\n",
    "\n",
    "scorer = make_scorer(f1_score, pos_label = 1)\n",
    "grid_search = GridSearchCV(estimator = logreg_classifier, param_grid = param_grid, cv = 5, scoring = scorer)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Наилучшие параметры:\", grid_search.best_params_)\n",
    "print(f'F1 с учетом сбалансированных классов: {grid_search.best_score_:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm--URZhTGQQ"
   },
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J0tm9o6RTHf-",
    "outputId": "8ef6bb38-29fd-467a-875f-2ee42a254679"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2],\n",
    "}\n",
    "\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "scorer = make_scorer(f1_score, pos_label = 1)\n",
    "grid_search = GridSearchCV(estimator = knn_classifier, param_grid = param_grid, cv = 5, scoring = scorer)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Наилучшие параметры:\", grid_search.best_params_)\n",
    "print(f'F1 с учетом сбалансированных классов: {grid_search.best_score_:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atU1_H6HUy0a"
   },
   "source": [
    "### Нейронная сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4aemZb9Xzy0"
   },
   "source": [
    "В этом разделе предлагается самостоятельно создать и обучить нейронную сеть, про интересные структуры вы можете посмотреть на последней странице статьи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hh1w2R0bSnA_"
   },
   "source": [
    "Напишем функцию для отрисовки кривых обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vkJMYrTDSkBR"
   },
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    fig, axs = plt.subplots(1, 2, figsize = (20, 7), facecolor = 'white')\n",
    "\n",
    "    axs[0].plot(history['loss_train'], label = 'train')\n",
    "    axs[0].plot(history['loss_val'], label = 'test')\n",
    "    axs[0].set_title('Loss')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].plot(history['metric_train'], label = 'train')\n",
    "    axs[1].plot(history['metric_val'], label = 'test')\n",
    "    axs[1].set_title('F1 Score')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_ylabel('F1 Score')\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UYJTNgdSzhO"
   },
   "source": [
    "Зададим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "id": "ypeum7sGQPin",
    "outputId": "b8c7e290-0c11-4112-9d66-0e5191114be0"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 16)\n",
    "        self.fc2 = nn.Linear(16, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class_weights = torch.FloatTensor([1, 10])\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "model = Net(input_size = X_train.shape[1])\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay = 0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 16\n",
    "history = {'loss_train': [], 'loss_val': [], 'metric_train': [], 'metric_val': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        X_batch = torch.FloatTensor(X_train[i:i+batch_size])\n",
    "        y_batch = torch.LongTensor(y_train[i:i+batch_size].values)\n",
    "\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs_train = model(torch.FloatTensor(X_train))\n",
    "        outputs_test = model(torch.FloatTensor(X_test))\n",
    "\n",
    "        _, predicted_train = torch.max(outputs_train, 1)\n",
    "        _, predicted_test = torch.max(outputs_test, 1)\n",
    "\n",
    "        loss_train = criterion(outputs_train, torch.LongTensor(y_train.values))\n",
    "        loss_test = criterion(outputs_test, torch.LongTensor(y_test.values))\n",
    "\n",
    "        metric_train = f1_score(y_train, predicted_train, average = 'weighted')\n",
    "        metric_test = f1_score(y_test, predicted_test, average = 'weighted')\n",
    "\n",
    "        history['loss_train'].append(loss_train.item())\n",
    "        history['loss_val'].append(loss_test.item())\n",
    "        history['metric_train'].append(metric_train)\n",
    "        history['metric_val'].append(metric_test)\n",
    "\n",
    "        clear_output(wait = True)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss_train: {loss_train.item():.2f}, Loss_val: {loss_test.item():.2f}, Metric_train: {metric_train:.2f}, Metric_val: {metric_test:.2f}')\n",
    "\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lym8LPldSZhy"
   },
   "source": [
    "Тестирование:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3WzSE2j8SY13",
    "outputId": "3674c657-dbad-4554-b08c-1490265a2c80"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(torch.FloatTensor(X_test))\n",
    "    test_loss = criterion(outputs, torch.LongTensor(y_test.values))\n",
    "    _, predicted_test = torch.max(outputs, 1)\n",
    "    test_metric = f1_score(y_test, predicted_test, average = 'weighted')\n",
    "    print(f\"Test Loss: {test_loss.item():.2f}, F1-score: {test_metric:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S94Q6wk8avIP"
   },
   "source": [
    "## Анализ полученных результатов и выводы по задаче"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SlKDK5geA0A"
   },
   "source": [
    "### Предобработка данных\n",
    "\n",
    "В процессе анализа данных мы обнаружили следующее:\n",
    "\n",
    "1. В основном признаки имеют распределение, близкое к нормальному.\n",
    "\n",
    "2. Присутствует значительное количество выбросов, которые были обработаны с использованием StandardScaler.\n",
    "\n",
    "3. В данных наблюдается дисбаланс между классами.\n",
    "\n",
    "### Обучение моделей\n",
    "\n",
    "При анализе данных решающим деревом были выделены 10 наиболее влиятельных признаков для последующего обучения. Затем был выполнен поиск по сетке параметров для каждой модели с целью достижения наилучшей точности. Однако метрики моделей оказались недостаточно высокими. Попытка воспроизвести подход, использованный в статье, не принесла улучшений в результатах.\n",
    "\n",
    "Далее мы решили провести обучение моделей на всем наборе данных, учитывая дисбаланс классов и подбирая параметры заранее. Следует отметить, что авторы статьи использовали Accuracy в качестве целевой метрики и достигли лучших результатов с помощью модели градиентного бустинга.\n",
    "\n",
    "Метрики полученных моделей:\n",
    "\n",
    "1. **Decision Tree:** 0.47\n",
    "2. **Random Forest:** 0.27\n",
    "3. **Logistic Regression:** 0.37\n",
    "4. **K-Nearest Neighbors:** 0.40\n",
    "5. **Multi-Layer Perceptron (MLP):** 0.64\n",
    "\n",
    "### Общий вывод по задаче\n",
    "\n",
    "Из полученных результатов видно, что наилучший показатель метрики F1 Score достигнут при использовании Multi-Layer Perceptron (MLP) модели. Таким образом, для данной задачи модель MLP является наилучшим выбором, обеспечивая наивысшую точность классификации молекул на токсичные и нетоксичные.\n",
    "\n",
    "Конечно, полученные показатели далеки от идеала. Что могло привести к этому:\n",
    "\n",
    "1. Неравномерное распределение классов существенно повлияло на результативность модели. Вероятно, я не учел этот дисбаланс должным образом при обучении.\n",
    "\n",
    "2. Возможно, недостаточное количество данных не позволило моделям достаточно эффективно обучиться.\n",
    "\n",
    "3. Также, вероятно, мне следовало провести более глубокий анализ данных перед обучением.\n",
    "\n",
    "### Комментарий\n",
    "\n",
    "Задача дейсвтительно классная, мне понравилось :) Только вот обидно, что в учебном курсе уделили всего лишь два семинара предобработке данных при дисбалансе классов. Возможно, из-за этого я не смог решить задачу так, как хотелось бы."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
