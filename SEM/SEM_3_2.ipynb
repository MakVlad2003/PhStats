{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvvBkP8CkwRc"
   },
   "source": [
    "## Регуляризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbL1CLP-kwRd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "sns.set_theme(font_scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6DWq8YtkwRf"
   },
   "source": [
    "### 0. Описание проблемы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGw-fsEJkwRf"
   },
   "source": [
    "**Линейная регрессия** - это  простая и хорошо интерпретируемая модель для работы с данными. Однако, как и всегда, нет ничего абсолютно универсального, и у всего есть свои недостатки.\n",
    "\n",
    "Довольно очевидной проблемой является то, что функциональная зависимость между фичами и таргетом может оказаться нелинейной. Тем не менее, даже, когда датасет, кажется, должен хорошо аппроксимироваться прямой, качество предсказаний может быть очень низким. Одним из возможных препятствий может оказаться мультиколлинеарность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGkscRqokwRf"
   },
   "source": [
    "**Мультиколлинеарность** - это наличие линейной или около линейной зависимости между признаками. Иначе говоря, между переменными может наблюдаться высокая корреляция, что в итоге приводит к неправильным (часто очень завышенным) коэффициентам модели.\n",
    "\n",
    "*К примеру, пусть есть переменная $y$, которую мы хотим научиться предсказывать при помощи переменных $x_1$, $x_2$ и $x_3$. Причем истинная зависимость выглядит просто как $y = x_1$. Однако нам могло не повезти, и величины могли оказаться линейно-зависимыми как-нибудь так: $x_1~+~x_2~-~2\\cdot~x_3 = 0$. В этом случае линейная модель не сможет различить между собой такие варианты коэффициентов как (1, 0, 0), (0, -1, 2), (101, 100, -200)... и, скорее всего, программа просто упадет, так как будет происходить обращение вырожденной матрицы (аналогично делению на ноль). В реальных данных чаще всего взаимосвязь между переменными является приблизительной (например, $x_2 \\approx 2 \\cdot x_3$), что формально не помешает применению линейной регрессии, но приведёт к неправдоподобно большим коэффициентам и плохой точности.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-a3jWpSkkwRf"
   },
   "source": [
    "Продемонстрируем данное явление на примере [датасета](https://www.nature.com/articles/s41598-020-76117-y) из последнего домашнего задания по экспрессиям различных генов (RNA-seq), используемых для предсказания возраста пациентов.\n",
    "\n",
    "*Данные были получены при помощи РНК секвенирования, которое для каждого образца считает число молекул РНК (различные изоформы могут как учитываться, так и нет), экспрессированных с генов. Таким образом получается таблица, в которой представлены различные образцы по одной оси и названия генов по другой. На пересечении стоит число детектированных молекул, которое иногда называют каунтом.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMRUwyRgkwRf"
   },
   "source": [
    "### 1. Метод наименьших квадратов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "rv-5SS_2kwRg",
    "outputId": "d372885f-a1f6-4b32-da9a-9c8fd0f82264"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Rnaseq_age_reg.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUF7WC8dkwRg"
   },
   "source": [
    "Выделим независимые и зависимую переменные и разобьем датасет на train и test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r7IeKu4-kwRh",
    "outputId": "1e0113eb-b282-4e76-be1a-70f704584412"
   },
   "outputs": [],
   "source": [
    "X, y = df.drop('Age', axis=1), df['Age']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAXclCjFkwRh"
   },
   "source": [
    "Сначала попробуем аппроксимировать данные линейной регрессией. Обучим модель, посчитаем коэффициент детерминации [$R^2$](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html), и MAPE на тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EadkrGz7kwRh",
    "outputId": "ce56eee4-2974-46f4-86d0-318564821eb7"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X = X_test)\n",
    "\n",
    "print(f'R2: {round(r2_score(y_test, y_pred), 2)} \\nMAPE: {round(mean_absolute_percentage_error(y_test, y_pred), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2daWT1gkwRh"
   },
   "source": [
    "**Вывод**: $R^2$ отрицательный, а MAPE составляет 200%. Модель никуда не годится."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQpGYTUGkwRi"
   },
   "source": [
    "### 2. Проверка мультиколлинеарности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCZR25g6kwRi"
   },
   "source": [
    "Проверим, не связаны ли между собой значения признаков. Самым простым вариантом является построение матрицы [коэффициентов корреляций](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient), показывающей наличие монотонных зависимостей между признаками. В библиотеке `seaborn` для её визуализации есть функция [`heatmap`](https://seaborn.pydata.org/generated/seaborn.heatmap.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VtpIckRkwRi"
   },
   "source": [
    "$$r_{pearson}(X, Y) = \\frac{\\sum_{i=1}^n(X_i - \\overline{X})(Y_i - \\overline{Y})}{\\sqrt{\\sum_{i=1}^n(Y_i - \\overline{Y})^2}\\sqrt{\\sum_{i=1}^n(Y_i - \\overline{Y})^2}} = \\frac{cov(X, Y)}{S_X \\cdot S_Y},$$\n",
    "где $X$ и $Y$ - векторы значений двух признаков длины $n$, $S$ - выборочные среднеквадратичные отклонения,  $cov$ - выборочная ковариация, $\\overline{X}$ и $\\overline{Y}$ - выборочные средние $X$ и $Y$.\n",
    "\n",
    "Чем ближе $r_{pearson}$ к $\\pm1$, тем выше степень линейной зависимости между признаками. На графике это выглядит так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "0VWWWTZ2kwRi",
    "outputId": "4f0f7d51-566c-40f2-c09a-d9fa22cb3c19"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Отобразим зависимость между значениями двух слабокоррелирующих признаков\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.regplot(x=X[\"NM-004978\"], y=X[\"NM-001308178\"],\n",
    "            scatter_kws={\"color\": \"black\"}, line_kws={\"color\": \"red\"}, ci=None)\n",
    "\n",
    "plt.xlabel(\"Каунты NM-004978\")\n",
    "plt.ylabel(\"Каунты NM-001308178\")\n",
    "\n",
    "weak_corr = np.corrcoef(X[\"NM-004978\"], X[\"NM-001308178\"])[0, 1]\n",
    "plt.title(f\"Слабая корреляция r = {weak_corr:.2f}\")\n",
    "\n",
    "# Отобразим зависимость между значениями двух сильнокоррелирующих признаков\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.regplot(x=X[\"NM-030919\"], y=X[\"NM-001297655\"],\n",
    "            scatter_kws={\"color\": \"black\"}, line_kws={\"color\": \"red\"}, ci=None)\n",
    "\n",
    "plt.xlabel(\"Каунты NM-030919\")\n",
    "plt.ylabel(\"Каунты NM-001297655\")\n",
    "\n",
    "strong_corr = np.corrcoef(X[\"NM-030919\"], X[\"NM-001297655\"])[0, 1]\n",
    "plt.title(f\"Сильная корреляция r = {strong_corr:.2f}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "id": "3LPg9msakwRi",
    "outputId": "ec76beb6-fee4-4f83-b7a4-feb925d3f597"
   },
   "outputs": [],
   "source": [
    "# Считаем корреляции между генами и визуализируем что получилось\n",
    "plt.figure(figsize=(7, 5))\n",
    "sns.heatmap(X_train.corr()).set(title=\"Корреляции между генами\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dz1cuoR-kwRi"
   },
   "source": [
    "Видно, что значения корреляций на обоих графиках очень высокие (где-то больше 0,8). Чтобы еще четче это увидеть, воспользуемся функцией [sns.clustermap](https://seaborn.pydata.org/generated/seaborn.clustermap.html), которая кластеризует/сортирует данные для лучшей визуализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "6VcoTMedkwRi",
    "outputId": "1efc1002-d499-4233-d743-db05834d7c83"
   },
   "outputs": [],
   "source": [
    "pearson_clusters = sns.clustermap(X_train.corr(), figsize=(7, 7))\n",
    "\n",
    "pearson_clusters.ax_row_dendrogram.set_visible(False) # Уберем дендрограммы\n",
    "pearson_clusters.ax_col_dendrogram.set_visible(False)\n",
    "pearson_clusters.figure.suptitle(\"Корреляции между генами\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsiLgf2WkwRj"
   },
   "source": [
    "Светлый цвет соответствует сильной корреляции. Видно, что среди признаков много линейно-зависимых. Это довольно типично для bulk RNA-seq, поскольку число генов обычно много больше числа образцов. Посмотрим, как выглядят зависимости между значениями сильно- и слабокоррелирующих признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRQuegowkwRj"
   },
   "source": [
    "<style>\n",
    "   .semi {\n",
    "    opacity: 0.6; /* Полупрозрачность элемента */\n",
    "   }\n",
    "</style>\n",
    "\n",
    "<div class=\"semi\">\n",
    "   <h4>\n",
    "2* VIF\n",
    "   </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KlTLXG-kwRj"
   },
   "source": [
    "<style>\n",
    "   .semi {\n",
    "    opacity: 0.6; /* Полупрозрачность элемента */\n",
    "    font-size: 11.5pt;\n",
    "   }\n",
    "</style>\n",
    "\n",
    "<div class=\"semi\">\n",
    "\n",
    "  Другим способом продемонстрировать мультиколлинеарность является коэффициент VIF (Variance Inflation Factor). Мы будем строить линейную модель, используя в качестве целевой переменной один из признаков (генов), а остальные в качестве независимых переменных. То есть мы проверяем, существует ли между признаками линейная зависимость. Метрика определяется следующим образом: $$VIF_i = \\frac{1}{1 - R_i^2},$$ где $R_i^2$ - это значение $R^2$ для линейной регрессии i-го гена по остальным. Считается, что\n",
    "  - VIF = 1 &mdash; переменные не коррелируют;\n",
    "  - 1 < VIF < 10 &mdash; переменные коррелируют частично;\n",
    "  - VIF > 10 &mdash; переменные коррелируют очень сильно.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "mtVAaPRikwRj",
    "outputId": "e8925ea1-e408-42ce-c6d7-43c70a3286bd"
   },
   "outputs": [],
   "source": [
    "genes = X_train.columns.to_list() # Создаем список всех генов из нашей таблички\n",
    "VIFs = np.array([]) # Список, в котором мы будем хранить значения VIF для каждого гена\n",
    "\n",
    "for gene in genes:\n",
    "    X_VIF, y_VIF = X_train.drop(gene, axis=1), X_train[gene]\n",
    "\n",
    "    # Не пользуемся данными теста (X_test, y_test), так как мы исследуем свойства нашего датасета, а не подгоняемся под него\n",
    "    X_train_VIF, X_test_VIF, y_train_VIF, y_test_VIF = train_test_split(X_VIF, y_VIF, test_size=0.2, train_size=0.8, random_state=42)\n",
    "\n",
    "    model_VIF = LinearRegression()\n",
    "    model_VIF.fit(X_train_VIF, y_train_VIF)\n",
    "\n",
    "    r2 = r2_score(y_test_VIF, model_VIF.predict(X_test_VIF))\n",
    "\n",
    "    VIFs = np.append(VIFs, 1 / (1 - r2))\n",
    "\n",
    "# Посчитаем долю (в %) генов по пороговым значениями\n",
    "VIFs_high_ratio = round((VIFs > 10).sum() / VIFs.shape[0], 2) * 100\n",
    "VIFs_moderate_ratio = round(((VIFs > 1) & (VIFs < 10)).sum() / VIFs.shape[0], 2) * 100\n",
    "VIFs_no_ratio = round((VIFs == 1).sum() / VIFs.shape[0], 2) * 100\n",
    "\n",
    "# Визуализируем наши результаты\n",
    "plt.figure(figsize=(6.5, 4))\n",
    "\n",
    "hist = sns.histplot(VIFs, bins=20)\n",
    "hist.axes.set_title(\"Гистограмма распределения VIFs\", fontsize=17)\n",
    "plt.annotate(f\"Доля VIF > 10: {VIFs_high_ratio:.0f}% \\nДоля 1 < VIF < 10: {VIFs_moderate_ratio:.0f}% \\nДоля VIF = 1: {VIFs_no_ratio:.0f}%\", xy=(0.475, 0.63), xycoords='axes fraction',\n",
    "             fontsize=14.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8VABMt3kwRj"
   },
   "source": [
    "<style>\n",
    "   .semi {\n",
    "    opacity: 0.6; /* Полупрозрачность элемента */\n",
    "    font-size: 11.5pt;\n",
    "   }\n",
    "</style>\n",
    "\n",
    "<div class=\"semi\">\n",
    "\n",
    "В нашем случае мы получаем очень большие VIF, что означает наличие значительной линейной зависимости между признаками в датасете.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBwoyNlkkwRj"
   },
   "source": [
    "### 3. Регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybxBcB77kwRj"
   },
   "source": [
    "Чтобы бороться с проблемой мультиколлинеарности, можно использовать модификации линейной модели, которые добавляют штраф за слишком большие значения коэффициентов регрессии в функцию потерь. Этот процесс называется регуляризацией. Самыми распространенными являются $l_1$ и $l_2$ регуляризации. В задаче регрессии ими обладают модели\n",
    " [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html), [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) и [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html).\n",
    "\n",
    "* **Ridge** &mdash; это модель линейной регрессии, которая минимизирует функционал $\\lVert y - X \\theta\\rVert^2_2 + \\alpha \\cdot \\lVert\\theta\\rVert^2_2$, где $y$ &mdash; истинные значения целевой переменной, $X$ &mdash; матрица \"объект-признак\", $\\theta$ &mdash; параметры модели, $\\alpha$ &mdash; параметр регуляризации.  \n",
    "* **Lasso**-регрессия минимизирует $\\lVert y - X \\theta\\rVert^2_2 + \\alpha \\cdot \\lVert\\theta\\rVert_1$   \n",
    "* **Elastic**-регрессия минимизирует $\\lVert y - X\\theta\\rVert^2_2 + \\alpha_1 \\cdot \\lVert\\theta\\rVert_1 + \\alpha_2 \\cdot \\lVert\\theta\\rVert^2_2$. Таким образом Elastic-регрессия является компромиссом между $l_1$ и $l_2$ регуляризациями (т. е. между Lasso- и Ridge-регрессиями)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEnbgBqNkwRk"
   },
   "source": [
    "####  Стандартизация (=нормализация)\n",
    "Перед тем как пользоваться этими моделями наши данные нужно сначала преобразовать. Регуляризация использует в своей реализации значения коэффициентов модели, а значит, они должны быть сопоставимы между собой, иметь одинаковый масштаб. Для этого воспользуемся классом [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html), который из каждого значения признака (то есть по столбцам в нашем случае) вычитает его среднее значение по всем образцам и потом делит на среднеквадратичное отклонение. Это позволяет убедиться, что все признаки имеют среднее и дисперсию равные 0 и 1, соответственно.\n",
    "\n",
    "Также на практике часто пользуются другой нормализацией &mdash; [MinMaxscaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html), которая позволяет перевести все значения переменной в фиксированный диапазон, к примеру, [0, 1] или [-1, 1]. Однако сейчас нам она не нужна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsLbpjQ-kwRk"
   },
   "source": [
    "$$StandardScaler: x_{ij}' = \\frac{x_{ij} - \\mu_j}{S_j};$$\n",
    "\n",
    "$$MinMaxScaler: x_{ij}' = \\frac{x_{ij} - m_j}{M_j - m_j},$$\n",
    "где $x_{ij}$ и $x_{ij}'$ - значения признака $j$ для объекта $i$ до и после стандартизации, $\\mu_j$ - выборочное среднее значение признака $j$, $S^2_j$ -  его выборочная дисперсия, $m_j$ и $M_j$ - минимальное и максимальное значения признака j по всем объектам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AOkcooVKkwRk"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Нормируем train и test. Не забываем, что нельзя применять\n",
    "# метод fit для тестовой выборки, чтобы модель ничего не знала о тестовых данных.\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)   # писать .fit_transform(X_test) КАТЕГОРИЧЕСКИ запрещается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6TzvgXrkwRk"
   },
   "source": [
    "Теперь рассмотрим все варианты регуляризаций и поймем, как значения гиперпараметров влияют на качество результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68noukFZkwRk"
   },
   "source": [
    "#### Практика\n",
    "#### 3.1 Ridge-регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EON__v5LkwRk"
   },
   "source": [
    "Создадим модель Ridge-регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sw09oMVekwRl"
   },
   "outputs": [],
   "source": [
    "model_ridge = Ridge(\n",
    "    # коэффициент регуляризации, чем больше - тем сильнее регуляризация (default = 1.0)\n",
    "    alpha=1.0,\n",
    "\n",
    "    # использовать ли параметр-остаток при обучении (default = True)\n",
    "    fit_intercept=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kn1C8xdCkwRl"
   },
   "source": [
    "Обучите эту модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "mlEJzvAnkwRl",
    "outputId": "b73b16b2-f23c-4052-d14c-e3354cb57557"
   },
   "outputs": [],
   "source": [
    "model_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xG1ZfjjqkwRl"
   },
   "source": [
    "Выведите перые двадцать коэффициентов модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7WVl0YtkwRl",
    "outputId": "e43e2808-7c37-4ca4-e332-374d61f8f7d0"
   },
   "outputs": [],
   "source": [
    "print(model_ridge.coef_[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FLhXmD6kwRl"
   },
   "source": [
    "Выведите значение свободного параметра:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GkvS1Ht9kwRt",
    "outputId": "1a7edd92-a787-4f70-fcea-d52235f59194"
   },
   "outputs": [],
   "source": [
    "print(model_ridge.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z27nyvPOkwRu"
   },
   "source": [
    "Выведите настройки модели, использованные при обучении, при помощи метода `get_params`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hJI1xk0kkwRu",
    "outputId": "9441cb03-4231-43f5-baed-5d07ea4b4a54"
   },
   "outputs": [],
   "source": [
    "model_ridge.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ANIlbxQkwRu"
   },
   "source": [
    "Сделайте предсказания модели по `X_test` и посчитайте метрики $R^2$ и MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sVACZPVnkwRu",
    "outputId": "de3dc1bd-de26-4ac7-fd50-9eff0f58916b"
   },
   "outputs": [],
   "source": [
    "y_pred = model_ridge.predict(X_test)\n",
    "\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "print(rf'R^2 для модели: {R2}')\n",
    "\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "print(f'MAPE: {mape:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3jBqRQXkwRu"
   },
   "source": [
    "Теперь создадим функцию для визуализации наших результатов, чтобы проследить, как меняются предсказания в зависимости от параметров моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LlL0GjgSkwRu"
   },
   "outputs": [],
   "source": [
    "# на этапе выполнения семинара в данный код можно не смотреть\n",
    "\n",
    "def linear_predictor(alpha, model, count_of_objects=20):\n",
    "    \"\"\"Данная функция строит график предсказаний модели\n",
    "    на первых count_of_objects объектах датасета.\n",
    "\n",
    "    :param alpha: коэффициент регуляризации\n",
    "    :param model: тип модели\n",
    "    \"\"\"\n",
    "    # Выберем тип модели\n",
    "    if model == 'Ridge':\n",
    "        model = Ridge(alpha=alpha, fit_intercept=True, max_iter=100, tol=0.0001)\n",
    "    elif model == 'Lasso':\n",
    "        # см. ниже по ноутбуку\n",
    "        model = Lasso(alpha=alpha, fit_intercept=True, max_iter=100, tol=0.0001)\n",
    "    elif model == 'Elastic':\n",
    "        # см. ниже по ноутбуку\n",
    "        model = ElasticNet(alpha=alpha, fit_intercept=True, max_iter=100, tol=0.0001)\n",
    "\n",
    "    # Обучим модель и посчитаем ее предсказания\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Отобразим истинные значения таргета и предсказанные нашей моделью\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.scatter(np.arange(count_of_objects), y_pred[:count_of_objects],\n",
    "              color='#0066FF', label='Предсказания модели')\n",
    "    plt.plot(np.arange(count_of_objects), y_pred[:count_of_objects],\n",
    "          color='#0066FF')\n",
    "    plt.scatter(np.arange(count_of_objects), y_test[:count_of_objects],\n",
    "                color='#FF3300', label='Истинные значения')\n",
    "\n",
    "    plt.grid(ls=':')\n",
    "    plt.xlabel('Номер объекта', fontsize=19)\n",
    "    plt.xticks(np.arange(count_of_objects))\n",
    "    plt.ylabel('Предсказание', fontsize=19)\n",
    "    plt.title('Предсказания на {} объектах'.format(count_of_objects),\n",
    "              fontsize=22)\n",
    "    plt.legend(fontsize=19)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547,
     "referenced_widgets": [
      "613c39e6bf2842709cf4a7df34e9e191",
      "f55c42a6a7aa4f2aa79622f8c2638a8a",
      "c9f6269d5272469c979e68b21423cd50",
      "2d85b07a326a4db1826e8db6e61bb466",
      "6de25cf1868048b981ebcaa76acbc833",
      "424baf78d82441ba9612b5343857d79d",
      "69378a5fe98b462aa002103c827b6869"
     ]
    },
    "id": "HvxmypWukwRu",
    "outputId": "47f4ea99-0668-4908-c58d-24ce6ac618a2"
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "# Создадим виджет, но не будем отображать его\n",
    "ip = widgets.interactive(\n",
    "    linear_predictor,\n",
    "    alpha=widgets.FloatSlider(min=0.0001, max=2, step=0.01, value=1),\n",
    "    model='Ridge'\n",
    ");\n",
    "\n",
    "# Выведем слайдер для изменения параметров модели\n",
    "display(widgets.HBox(ip.children[:1]))\n",
    "\n",
    "# Отобразим вывод функции\n",
    "display(ip.children[-1])\n",
    "ip.update() # Запуск функции до первого изменения слайдеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72JxRt6LkwRu"
   },
   "source": [
    "Сделайте выводы о роли параметра в Ridge-регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHSGa2g3kwRv"
   },
   "source": [
    "**Выводы:**\n",
    "\n",
    "Чем больше значение alpha, тем сильнее штраф, накладываемый на большие значения коэффициентов. С увеличением alpha модель становится более устойчивой к переобучению, но может потерять в точности предсказаний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1fBKgmokwRv"
   },
   "source": [
    "#### 3.2 Lasso-регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhkk9aOakwRv"
   },
   "source": [
    "Создадим модель Lasso-регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSUsM6G1kwRv"
   },
   "outputs": [],
   "source": [
    "model_lasso = Lasso(\n",
    "    # коэффициент регуляризации, чем больше - тем сильнее регуляризация (default = 1.0)\n",
    "    alpha=1.0,\n",
    "\n",
    "    # использовать ли параметр-остаток при обучении (default = True)\n",
    "    fit_intercept=True,\n",
    "\n",
    "    # максимальное количество итераций в методе оптимизации (default = 1000)\n",
    "    max_iter=1000,\n",
    "\n",
    "    # точность решения (не забываем, что Lasso использует итеративные методы решения)\n",
    "    # чем значение меньше, тем больше может потребоваться итераций (default = 1e-4)\n",
    "    tol=0.0001,\n",
    "\n",
    "    # использовать ли предпосчитанную матрицу Грамма для ускорения расчетов (default = False)\n",
    "    precompute=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GC-wBIabkwRv"
   },
   "source": [
    "Обучите эту модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "FpTPKiDXkwRv",
    "outputId": "ac4af7c4-cf1f-4211-933b-8a3a2b7fde6a"
   },
   "outputs": [],
   "source": [
    "model_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-VLhF8GkwRv"
   },
   "source": [
    "Выведите первые двадцать коэффициентов модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CgOT5Tj-kwRv",
    "outputId": "92baf096-54b2-4661-98e1-e144c1220580"
   },
   "outputs": [],
   "source": [
    "print(model_lasso.coef_[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nhe-JQAlkwRw"
   },
   "source": [
    "Выведите значение свободного параметра (intercept):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJBU0s3KkwRw",
    "outputId": "527050b0-07e5-4a48-94f6-3f1ed34e31f0"
   },
   "outputs": [],
   "source": [
    "print(model_lasso.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59FQWEDkkwRw"
   },
   "source": [
    "Вместо обычного списка коэффициентов Lasso хранит в себе их [разреженное представление](https://python-school.ru/blog/python/sparse-matrix/), то есть только ненулевые элементы. Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8mLrVvTkwRw"
   },
   "source": [
    "**Ответ:**\n",
    "\n",
    "L1 мера в Lasso регуляризации зануляет коэффициенты, которые вносят малый вклад, поэтому у нас получилось много нулевых элементов.\n",
    "И тогда встает вопрос об оптимальном хранении такой матрицы, чтобы сэкономить память вместо всех коэффициентов хранится разреженная матрица, которая указывает только на ненулевые коэффициенты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GseIrKu9kwRw"
   },
   "source": [
    "Напечатайте значение этого объекта, которое хранится в `sparse_coef_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6iQcA5DkwRw",
    "outputId": "107f433e-6bb1-44d0-f366-cfb8e8d3da6e"
   },
   "outputs": [],
   "source": [
    "print(model_lasso.sparse_coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9AKvlHokwRw"
   },
   "source": [
    "Сделайте предсказания модели по `X_test` и посчитайте метрики $R^2$ и MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KLGFKvMbkwRw",
    "outputId": "4804a4d7-19c7-4711-a1ae-6bdfd4b45f23"
   },
   "outputs": [],
   "source": [
    "y_pred = model_lasso.predict(X_test)\n",
    "\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "print(rf'R^2 для модели: {R2}')\n",
    "\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "print(f'MAPE: {mape:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VE05mZAskwRw"
   },
   "source": [
    "Визуализируем данные аналогично примеру с Ridge-регрессией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547,
     "referenced_widgets": [
      "641076a4ad2f4f33aee3394c0bae23c4",
      "79a510dadb8a448b9352b967d0f39049",
      "991ccb8a62ba4531881afe3079e34537",
      "67f5d9c27f424803956b1e9046a559d0",
      "2ea66886b4164058b56dbb1572ff7f8d",
      "6a0e6157ab07462484915fc192eec4ec",
      "59a6ef1b2c0645a79000ae60346dc7c2"
     ]
    },
    "id": "0JED8rU0kwRx",
    "outputId": "9077d6bf-2a2e-4931-97ec-cfab62731489"
   },
   "outputs": [],
   "source": [
    "# Создадим виджет, но не будем отображать его\n",
    "ip = widgets.interactive(\n",
    "    linear_predictor,\n",
    "    alpha=widgets.FloatSlider(min=0.0001, max=15, step=0.1, value=1),\n",
    "    model='Lasso'\n",
    ");\n",
    "\n",
    "# Выведем слайдер для изменения параметров модели\n",
    "display(widgets.HBox(ip.children[:1]))\n",
    "\n",
    "# Отобразим вывод функции\n",
    "display(ip.children[-1])\n",
    "ip.update() # Запуск функции до первого изменения слайдеров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIVXCkpokwRx"
   },
   "source": [
    "Сделайте выводы о роли параметра в Lasso-регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9X5WjatkwRx"
   },
   "source": [
    "**Выводы:**\n",
    "\n",
    "Увеличение значения alpha в Lasso-регрессии приводит к увеличению силы регуляризации. Это может помочь уменьшить переобучение модели, особенно в случае наличия мультиколлинеарности в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hthslrkUkwRx"
   },
   "source": [
    "#### 3.3 Elastic-регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiTGlXskkwRx"
   },
   "source": [
    "Теперь разберемся аналогично с ElasticNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89XpvNMgkwRx"
   },
   "outputs": [],
   "source": [
    "model_elastic = ElasticNet(\n",
    "    # коэффициент регуляризации, чем больше - тем сильнее регуляризация (default = 1.0)\n",
    "    alpha=0.01,\n",
    "\n",
    "    # какой регуляризации отдавать предпочтение: l1, а не l2 (default = 0.5)\n",
    "    l1_ratio=0.6,\n",
    "\n",
    "    # использовать ли параметр-остаток при обучении (default = True)\n",
    "    fit_intercept=True,\n",
    "\n",
    "    # максимальное количество итераций в методе оптимизации (default = 1000)\n",
    "    max_iter=5000,\n",
    "\n",
    "    # точность решения,\n",
    "    # чем значение меньше, тем больше может потребоваться итераций (default = 1e-4)\n",
    "    tol=0.0001,\n",
    "\n",
    "    # использовать ли предпосчитанную матрицу Грамма для ускорения расчетов (default = False)\n",
    "    precompute=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjXKYelOkwRx"
   },
   "source": [
    "Вот так выглядит связь между `alpha`, `l1_ratio` и $\\alpha_1, \\alpha_2$, которые мы вводили:\n",
    "\n",
    "$$\n",
    "\\verb|alpha| = \\alpha_1 + 2\\alpha_2 \\cdot\n",
    "\\\\\n",
    "\\verb|l1_ratio| = \\frac{\\alpha_1}{\\alpha_1 + 2\\alpha_2}\n",
    "\\\\\n",
    "\\alpha_1 = \\verb|alpha| \\cdot \\verb|l1_ratio|\\cdot\n",
    "\\\\\n",
    "\\alpha_2 = \\frac{1}{2} \\verb|alpha| \\cdot (1 - \\verb|l1_ratio|)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAHVtID2kwRy"
   },
   "source": [
    "Обучите модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "Ebo_d43UkwRy",
    "outputId": "15aa08c3-c66f-4969-8568-7d7440f655ac"
   },
   "outputs": [],
   "source": [
    "model_elastic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjFCzs-CkwRy"
   },
   "source": [
    "Выведите первые двадцать коэффициентов модели и значение свободного параметра (intercept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zrw4AhF8kwRy",
    "outputId": "ecade4fd-a932-4056-f3cc-0f253d03ade5"
   },
   "outputs": [],
   "source": [
    "print(model_elastic.coef_[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtEoT3MdkwRy",
    "outputId": "926dead0-c3ec-4457-feee-dc3e64ab55a6"
   },
   "outputs": [],
   "source": [
    "print(model_elastic.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNodirtRkwRy"
   },
   "source": [
    "Напечатайте, как выглядит разреженное представление коэффициентов. Есть ли разница по сравнению с Lasso? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5IrRg1KEkwRy",
    "outputId": "b7ca388c-7aa5-45ef-ea7e-2d6e554234b8"
   },
   "outputs": [],
   "source": [
    "print(model_elastic.sparse_coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzYk9g_pkwRy"
   },
   "source": [
    "**Ответ:**\n",
    "\n",
    "По сравнению с Lasso мы имеем меньшее число нулевых элементов => более мягкий способ регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0p2wWm5ykwRy"
   },
   "source": [
    "Сделайте предсказания модели по `X_test` и посчитайте метрики $R^2$ и MAPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkOXad1TkwRz",
    "outputId": "e34a4620-1ba6-4ee0-8458-a1134d5744b7"
   },
   "outputs": [],
   "source": [
    "y_pred = model_elastic.predict(X_test)\n",
    "\n",
    "R2 = r2_score(y_test, y_pred)\n",
    "print(rf'R^2 для модели: {R2}')\n",
    "\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "print(f'MAPE: {mape:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePLck2gckwRz"
   },
   "source": [
    "Визуализируем наши данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaA3wLQGkwRz"
   },
   "source": [
    "#### 3.4 Сравнение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JWvq46PkwRz"
   },
   "source": [
    "Сделайте выводы. В чем отличие моделей друг от друга? Также сравните между собой линейную и регуляризованные модели для датасета по РНК-секвенированию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daxVTSIRkwRz"
   },
   "source": [
    "**Выводы:**\n",
    "\n",
    "**L1 (Lasso) регуляризация:**\n",
    "\n",
    "Сильный метод регуляризации, который добавляет штраф к сумме абсолютных значений коэффициентов.\n",
    "Способствует разреженности модели, что позволяет автоматически отбирать наиболее важные признаки и устанавливать некоторые коэффициенты в нулевые значения.\n",
    "Чувствителен к выбору параметра регуляризации (alpha) и может занулять коэффициенты при неправильном подборе.\n",
    "\n",
    "**L2 (Ridge) регуляризация:**\n",
    "\n",
    "Добавляет штраф к сумме квадратов коэффициентов.\n",
    "Помогает предотвратить мультиколлинеарность и уменьшить влияние больших значений коэффициентов.\n",
    "Все коэффициенты остаются ненулевыми, и они уменьшаются пропорционально, но не зануляются.\n",
    "\n",
    "**ElasticNet:**\n",
    "\n",
    "Совмещает в себе L1 и L2 регуляризацию, добавляя как штраф к абсолютным значениям, так и к квадратам коэффициентов.\n",
    "Объединяет преимущества обеих регуляризаций и может быть полезен, когда неизвестно, какая из них предпочтительнее.\n",
    "\n",
    "**Общий вывод:**\n",
    "\n",
    "Выбор между L1, L2 и ElasticNet зависит от специфики данных и задачи.\n",
    "Подбор оптимальных параметров регуляризации очень важен.\n",
    "ElasticNet может быть предпочтительным в ситуациях, когда неясно, какая форма регуляризации более подходит."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
